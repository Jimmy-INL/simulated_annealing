{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T09:33:29.620158Z",
     "start_time": "2018-05-14T09:33:28.910654Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T09:33:29.663950Z",
     "start_time": "2018-05-14T09:33:29.658543Z"
    }
   },
   "outputs": [],
   "source": [
    "from simulated_annealing import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T09:33:33.783783Z",
     "start_time": "2018-05-14T09:33:30.220755Z"
    }
   },
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('data/creditcardfraud.zip', compression='zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T09:33:34.281310Z",
     "start_time": "2018-05-14T09:33:34.196524Z"
    }
   },
   "outputs": [],
   "source": [
    "x_tr, test = train_test_split(raw_df, test_size=0.2, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T09:33:35.171037Z",
     "start_time": "2018-05-14T09:33:35.105116Z"
    }
   },
   "outputs": [],
   "source": [
    "train, valid = train_test_split(x_tr, test_size=0.25, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T09:33:36.523611Z",
     "start_time": "2018-05-14T09:33:36.490091Z"
    }
   },
   "outputs": [],
   "source": [
    "xtrain, ytrain = train.drop('Class', axis=1), train['Class']\n",
    "xvalid, yvalid = valid.drop('Class', axis=1), valid['Class']\n",
    "xtest, ytest = test.drop('Class', axis=1), test['Class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost DMatrix Inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T09:33:38.494580Z",
     "start_time": "2018-05-14T09:33:38.366908Z"
    }
   },
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(xtrain, label=ytrain)\n",
    "dvalid = xgb.DMatrix(xvalid, label=yvalid)\n",
    "dtest = xgb.DMatrix(xtest, label=ytest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annealing Functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T09:33:40.514213Z",
     "start_time": "2018-05-14T09:33:40.511177Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parameters that are kept constant during the tuning process\n",
    "param = {'silent':1,\n",
    "         'min_child_weight':1, # Defines the minimum sum of weights of all observations required in a child\n",
    "         'objective':'binary:logistic',\n",
    "         'eval_metric':'auc',\n",
    "         'seed': 42}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T09:33:42.406457Z",
     "start_time": "2018-05-14T09:33:42.400535Z"
    }
   },
   "outputs": [],
   "source": [
    "# Parameter search space\n",
    "tune_dic = OrderedDict()\n",
    "tune_dic['max_depth']= [5,10,15,20,25] ## maximum tree depth\n",
    "tune_dic['subsample']=[0.5,0.6,0.7,0.8,0.9,1.0] ## proportion of training instances used in trees\n",
    "tune_dic['colsample_bytree']= [0.5,0.6,0.7,0.8,0.9,1.0] ## subsample ratio of columns\n",
    "tune_dic['eta']= [0.01,0.05,0.10,0.20,0.30,0.40]  ## learning rate\n",
    "tune_dic['gamma']= [0.00,0.05,0.10,0.15,0.20]  ## minimum loss function reduction required for a split\n",
    "tune_dic['scale_pos_weight']=[30,40,50,300,400,500,600,700] ## relative weight of positive/negative instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T09:33:44.426157Z",
     "start_time": "2018-05-14T09:33:44.415613Z"
    }
   },
   "outputs": [],
   "source": [
    "# Custom metric calculation function\n",
    "def f2_score(y_pred, y_true): return fbeta_score(y_true, (y_pred>=0.5).astype(int), beta=2)\n",
    "\n",
    "# Function to train model\n",
    "def train_model(curr_params, param, Xtrain, Xvalid, Ytrain=None, Yvalid=None, metric=f2_score, num_rounds=20):\n",
    "    \"\"\"\n",
    "    Train the model with given set of hyperparameters\n",
    "    curr_params - Dict of hyperparameters and chosen values\n",
    "    param - Dict of hyperparameters that are kept constant\n",
    "    Xtrain - DMatrix of traing data\n",
    "    Ytrain - Training labels\n",
    "    Ytrain - DMatrix of validation data\n",
    "    Yvalid - Validaion labels\n",
    "    metric - Metric to compute model performance on\n",
    "    num_rounds - Number of boosting rounds\n",
    "    \"\"\"\n",
    "    param.update(curr_params)\n",
    "    model = xgb.train(param, Xtrain, num_boost_round=num_rounds)\n",
    "    preds = model.predict(Xvalid)\n",
    "    labels = Xvalid.get_label()\n",
    "    metric_val = metric(preds, labels)\n",
    "    \n",
    "    return model, metric_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-14T09:40:11.806918Z",
     "start_time": "2018-05-14T09:38:05.078064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Iteration 0\n",
      "Local Improvement in metric from  -1.0000 to   0.7739 - parameters accepted\n",
      "Global improvement in metric from  -1.0000 to   0.7739 - best parameters updated\n",
      "Starting Iteration 1\n",
      "Local Improvement in metric from   0.7739 to   0.7841 - parameters accepted\n",
      "Global improvement in metric from   0.7739 to   0.7841 - best parameters updated\n",
      "Starting Iteration 2\n",
      "Combination revisited\n",
      "No Improvement but parameters accepted. Metric change:   0.0000 \n",
      "                threshold: 1.0000 random number: 0.5847\n",
      "                \n",
      "Starting Iteration 3\n",
      "No Improvement but parameters accepted. Metric change:  -0.0086 \n",
      "                threshold: 0.9676 random number: 0.1444\n",
      "                \n",
      "Starting Iteration 4\n",
      "No Improvement but parameters accepted. Metric change:   0.0000 \n",
      "                threshold: 1.0000 random number: 0.2147\n",
      "                \n",
      "Starting Iteration 5\n",
      "Local Improvement in metric from   0.7755 to   0.7857 - parameters accepted\n",
      "Global improvement in metric from   0.7841 to   0.7857 - best parameters updated\n",
      "Starting Iteration 6\n",
      "No Improvement but parameters accepted. Metric change:  -0.0016 \n",
      "                threshold: 0.9928 random number: 0.2641\n",
      "                \n",
      "Starting Iteration 7\n",
      "Local Improvement in metric from   0.7841 to   0.7943 - parameters accepted\n",
      "Global improvement in metric from   0.7857 to   0.7943 - best parameters updated\n",
      "Starting Iteration 8\n",
      "No Improvement but parameters accepted. Metric change:  -0.0070 \n",
      "                threshold: 0.9691 random number: 0.9026\n",
      "                \n",
      "Starting Iteration 9\n",
      "No Improvement but parameters accepted. Metric change:  -0.0070 \n",
      "                threshold: 0.9689 random number: 0.7330\n",
      "                \n"
     ]
    }
   ],
   "source": [
    "res = simulate_annealing(train_model, tune_dic, param, dtrain, dvalid, maxiters=10, train_dict={'num_rounds':50})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py36]",
   "language": "python",
   "name": "conda-env-py36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
